{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5449ea86-ff90-45e0-a606-acba66cf853b",
   "metadata": {},
   "source": [
    "# CNN with Embeddings on Post Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d1df4-f7eb-4a06-96b1-f42a9cdf45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f6a3e3-c615-4f78-80f8-806b92882c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jaredfeldman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jaredfeldman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# tf and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for stop words\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a5dfc6-23be-4461-a6c3-2cd693f8e517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>giver_username_if_known</th>\n",
       "      <th>number_of_downvotes_of_request_at_retrieval</th>\n",
       "      <th>number_of_upvotes_of_request_at_retrieval</th>\n",
       "      <th>post_was_edited</th>\n",
       "      <th>request_id</th>\n",
       "      <th>request_number_of_comments_at_retrieval</th>\n",
       "      <th>request_text</th>\n",
       "      <th>request_text_edit_aware</th>\n",
       "      <th>request_title</th>\n",
       "      <th>requester_account_age_in_days_at_request</th>\n",
       "      <th>...</th>\n",
       "      <th>requester_received_pizza</th>\n",
       "      <th>requester_subreddits_at_request</th>\n",
       "      <th>requester_upvotes_minus_downvotes_at_request</th>\n",
       "      <th>requester_upvotes_minus_downvotes_at_retrieval</th>\n",
       "      <th>requester_upvotes_plus_downvotes_at_request</th>\n",
       "      <th>requester_upvotes_plus_downvotes_at_retrieval</th>\n",
       "      <th>requester_user_flair</th>\n",
       "      <th>requester_username</th>\n",
       "      <th>unix_timestamp_of_request</th>\n",
       "      <th>unix_timestamp_of_request_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_l25d7</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi I am in need of food for my 4 children we a...</td>\n",
       "      <td>Hi I am in need of food for my 4 children we a...</td>\n",
       "      <td>Request Colorado Springs Help Us Please</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>nickylvst</td>\n",
       "      <td>1317852607</td>\n",
       "      <td>1317849007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N/A</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_rcb83</td>\n",
       "      <td>0</td>\n",
       "      <td>I spent the last money I had on gas today. Im ...</td>\n",
       "      <td>I spent the last money I had on gas today. Im ...</td>\n",
       "      <td>[Request] California, No cash and I could use ...</td>\n",
       "      <td>501.111100</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[AskReddit, Eve, IAmA, MontereyBay, RandomKind...</td>\n",
       "      <td>34</td>\n",
       "      <td>4258</td>\n",
       "      <td>116</td>\n",
       "      <td>11168</td>\n",
       "      <td>None</td>\n",
       "      <td>fohacidal</td>\n",
       "      <td>1332652424</td>\n",
       "      <td>1332648824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_lpu5j</td>\n",
       "      <td>0</td>\n",
       "      <td>My girlfriend decided it would be a good idea ...</td>\n",
       "      <td>My girlfriend decided it would be a good idea ...</td>\n",
       "      <td>[Request] Hungry couple in Dundee, Scotland wo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>jacquibatman7</td>\n",
       "      <td>1319650094</td>\n",
       "      <td>1319646494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>t3_mxvj3</td>\n",
       "      <td>4</td>\n",
       "      <td>It's cold, I'n hungry, and to be completely ho...</td>\n",
       "      <td>It's cold, I'n hungry, and to be completely ho...</td>\n",
       "      <td>[Request] In Canada (Ontario), just got home f...</td>\n",
       "      <td>6.518438</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[AskReddit, DJs, IAmA, Random_Acts_Of_Pizza]</td>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "      <td>None</td>\n",
       "      <td>4on_the_floor</td>\n",
       "      <td>1322855434</td>\n",
       "      <td>1322855434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N/A</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_1i6486</td>\n",
       "      <td>5</td>\n",
       "      <td>hey guys:\\n I love this sub. I think it's grea...</td>\n",
       "      <td>hey guys:\\n I love this sub. I think it's grea...</td>\n",
       "      <td>[Request] Old friend coming to visit. Would LO...</td>\n",
       "      <td>162.063252</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>[GayBrosWeightLoss, RandomActsOfCookies, Rando...</td>\n",
       "      <td>1121</td>\n",
       "      <td>1225</td>\n",
       "      <td>1733</td>\n",
       "      <td>1887</td>\n",
       "      <td>None</td>\n",
       "      <td>Futuredogwalker</td>\n",
       "      <td>1373657691</td>\n",
       "      <td>1373654091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  giver_username_if_known  number_of_downvotes_of_request_at_retrieval  \\\n",
       "0                     N/A                                            0   \n",
       "1                     N/A                                            2   \n",
       "2                     N/A                                            0   \n",
       "3                     N/A                                            0   \n",
       "4                     N/A                                            6   \n",
       "\n",
       "   number_of_upvotes_of_request_at_retrieval  post_was_edited request_id  \\\n",
       "0                                          1                0   t3_l25d7   \n",
       "1                                          5                0   t3_rcb83   \n",
       "2                                          3                0   t3_lpu5j   \n",
       "3                                          1                1   t3_mxvj3   \n",
       "4                                          6                0  t3_1i6486   \n",
       "\n",
       "   request_number_of_comments_at_retrieval  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        4   \n",
       "4                                        5   \n",
       "\n",
       "                                        request_text  \\\n",
       "0  Hi I am in need of food for my 4 children we a...   \n",
       "1  I spent the last money I had on gas today. Im ...   \n",
       "2  My girlfriend decided it would be a good idea ...   \n",
       "3  It's cold, I'n hungry, and to be completely ho...   \n",
       "4  hey guys:\\n I love this sub. I think it's grea...   \n",
       "\n",
       "                             request_text_edit_aware  \\\n",
       "0  Hi I am in need of food for my 4 children we a...   \n",
       "1  I spent the last money I had on gas today. Im ...   \n",
       "2  My girlfriend decided it would be a good idea ...   \n",
       "3  It's cold, I'n hungry, and to be completely ho...   \n",
       "4  hey guys:\\n I love this sub. I think it's grea...   \n",
       "\n",
       "                                       request_title  \\\n",
       "0            Request Colorado Springs Help Us Please   \n",
       "1  [Request] California, No cash and I could use ...   \n",
       "2  [Request] Hungry couple in Dundee, Scotland wo...   \n",
       "3  [Request] In Canada (Ontario), just got home f...   \n",
       "4  [Request] Old friend coming to visit. Would LO...   \n",
       "\n",
       "   requester_account_age_in_days_at_request  ...  requester_received_pizza  \\\n",
       "0                                  0.000000  ...                     False   \n",
       "1                                501.111100  ...                     False   \n",
       "2                                  0.000000  ...                     False   \n",
       "3                                  6.518438  ...                     False   \n",
       "4                                162.063252  ...                     False   \n",
       "\n",
       "                     requester_subreddits_at_request  \\\n",
       "0                                                 []   \n",
       "1  [AskReddit, Eve, IAmA, MontereyBay, RandomKind...   \n",
       "2                                                 []   \n",
       "3       [AskReddit, DJs, IAmA, Random_Acts_Of_Pizza]   \n",
       "4  [GayBrosWeightLoss, RandomActsOfCookies, Rando...   \n",
       "\n",
       "   requester_upvotes_minus_downvotes_at_request  \\\n",
       "0                                             0   \n",
       "1                                            34   \n",
       "2                                             0   \n",
       "3                                            54   \n",
       "4                                          1121   \n",
       "\n",
       "   requester_upvotes_minus_downvotes_at_retrieval  \\\n",
       "0                                               1   \n",
       "1                                            4258   \n",
       "2                                               3   \n",
       "3                                              59   \n",
       "4                                            1225   \n",
       "\n",
       "   requester_upvotes_plus_downvotes_at_request  \\\n",
       "0                                            0   \n",
       "1                                          116   \n",
       "2                                            0   \n",
       "3                                           76   \n",
       "4                                         1733   \n",
       "\n",
       "   requester_upvotes_plus_downvotes_at_retrieval  requester_user_flair  \\\n",
       "0                                              1                  None   \n",
       "1                                          11168                  None   \n",
       "2                                              3                  None   \n",
       "3                                             81                  None   \n",
       "4                                           1887                  None   \n",
       "\n",
       "   requester_username  unix_timestamp_of_request  \\\n",
       "0           nickylvst                 1317852607   \n",
       "1           fohacidal                 1332652424   \n",
       "2       jacquibatman7                 1319650094   \n",
       "3       4on_the_floor                 1322855434   \n",
       "4     Futuredogwalker                 1373657691   \n",
       "\n",
       "   unix_timestamp_of_request_utc  \n",
       "0                     1317849007  \n",
       "1                     1332648824  \n",
       "2                     1319646494  \n",
       "3                     1322855434  \n",
       "4                     1373654091  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "training_data = pd.read_json(\"train.json\")\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5f54a8-ab8f-46b6-95e8-1ba4b9d36460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate variables...\n",
    "#X_training_data = np.array(training_data.drop('requester_received_pizza', axis = 1))\n",
    "#print(X_training_data.shape)\n",
    "\n",
    "# ...from labels\n",
    "#Y_training_data = np.array(training_data['requester_received_pizza'])\n",
    "#print(Y_training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b33c95-7cda-4de7-a165-f47ac5595a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "request_text_edit_aware     object\n",
       "requester_received_pizza      bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_text = training_data[['request_text_edit_aware', 'requester_received_pizza']]\n",
    "training_data_text.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8479de64-22a3-43af-956b-407afebb1414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_text_edit_aware</th>\n",
       "      <th>requester_received_pizza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi I am in need of food for my 4 children we a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I spent the last money I had on gas today. Im ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My girlfriend decided it would be a good idea ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's cold, I'n hungry, and to be completely ho...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey guys:\\n I love this sub. I think it's grea...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4035</th>\n",
       "      <td>Is anyone out there kind enough to help me out...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>If someone could hook me up with a $15 gift ca...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>Have today off, soo I'll be stuck in the house...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4038</th>\n",
       "      <td>I've never done anything like this before, but...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4039</th>\n",
       "      <td>Like the title says, had to pay an unexpected ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                request_text_edit_aware  \\\n",
       "0     Hi I am in need of food for my 4 children we a...   \n",
       "1     I spent the last money I had on gas today. Im ...   \n",
       "2     My girlfriend decided it would be a good idea ...   \n",
       "3     It's cold, I'n hungry, and to be completely ho...   \n",
       "4     hey guys:\\n I love this sub. I think it's grea...   \n",
       "...                                                 ...   \n",
       "4035  Is anyone out there kind enough to help me out...   \n",
       "4036  If someone could hook me up with a $15 gift ca...   \n",
       "4037  Have today off, soo I'll be stuck in the house...   \n",
       "4038  I've never done anything like this before, but...   \n",
       "4039  Like the title says, had to pay an unexpected ...   \n",
       "\n",
       "      requester_received_pizza  \n",
       "0                        False  \n",
       "1                        False  \n",
       "2                        False  \n",
       "3                        False  \n",
       "4                        False  \n",
       "...                        ...  \n",
       "4035                     False  \n",
       "4036                      True  \n",
       "4037                     False  \n",
       "4038                     False  \n",
       "4039                     False  \n",
       "\n",
       "[4040 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71f9a9a4-087a-4c80-89cd-9fb374945a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#<_BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70db21df-65ff-458e-abb2-482291cf9075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "3046\n",
      "4040\n"
     ]
    }
   ],
   "source": [
    "posts_pizza = training_data_text[training_data_text['requester_received_pizza'] == True]\n",
    "posts_no_pizza = training_data_text[training_data_text['requester_received_pizza'] == False]\n",
    "\n",
    "print(len(posts_pizza))\n",
    "print(len(posts_no_pizza))\n",
    "print(len(posts_pizza) + len(posts_no_pizza))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cdfacc8-5b46-4725-aff7-ad67778aef95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "3046\n",
      "4040\n"
     ]
    }
   ],
   "source": [
    "posts_pizza_list = list(posts_pizza['request_text_edit_aware'])\n",
    "posts_no_pizza_list = list(posts_no_pizza['request_text_edit_aware'])\n",
    "\n",
    "print(len(posts_pizza_list))\n",
    "print(len(posts_no_pizza_list))\n",
    "print(len(posts_pizza_list) + len(posts_no_pizza_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35cc1497-fdbe-47fc-8153-3aa48d1e3701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# create files for each list\n",
    "# uncomment below to run but files already created and moved\n",
    "\n",
    "#for index, post in enumerate(posts_no_pizza_list):\n",
    "    #print(index)\n",
    "    #print(post)\n",
    "    #with io.open(\"file_\" + str(index) + \".txt\", 'w', encoding = 'utf-8') as f:\n",
    "        #f.write(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bc2db7a-ccdb-404a-953e-6c611b3a3eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jaredfeldman/Courses/MIDS207/free_pizza'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a78bd86a-4172-4a02-a538-e5cf56401f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1401 files belonging to 2 classes.\n",
      "Using 1261 files for training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'posts/posts_700', \n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.1, \n",
    "    subset='training', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a83f0b4-c3b5-4bbe-b4ac-6ad2809c2e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c8c5ee1-c361-4700-954c-aae7826213d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review b\"I have about 15.00 in Amazon payments credit and I don't feel like waiting for it to deposit into my account. I'm also craving some pizza...so, I was thinking I'd have some fun.\\n\\nWhoever orders me a pizza tonight and sends me their address will get a random gift chosen by me shipped to their house. It won't be a junk item, I will try to get creative and thoughtful with it. I won't tell you what it is so you'll just have to wait and see when it arrives.\\n\\nMy inspiration was a cross between RAOP and RAOA!\"\n",
      "Label 0\n",
      "Review b'I would like to request pizza this evening. A friend of mine is coming over to drop off Dexter Season 1 and she is not bringing me any food. I would like to wwtch this show with my young teens and enjoy some Papa Johns or similar. If anyone can help, thanks in advance.'\n",
      "Label 1\n",
      "Review b\"Pre-Law, if I make it through (wouldn't count on it if I were you but there's a chance) you get free law stuff. My ferrari lost its traction control and I lost my dads visa black card so hard to eat.\"\n",
      "Label 0\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(\"Review\", text_batch.numpy()[i])\n",
    "    print(\"Label\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cbdd449-311a-4eef-bc62-9ee9c0e7e886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to no_pizza_700\n",
      "Label 1 corresponds to pizza_700\n"
     ]
    }
   ],
   "source": [
    "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
    "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])\n",
    "#print(\"Label 2 corresponds to\", raw_train_ds.class_names[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03a3f6da-c65a-4887-86d8-6fb2e665f633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1401 files belonging to 2 classes.\n",
      "Using 140 files for validation.\n"
     ]
    }
   ],
   "source": [
    "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'posts/posts_700', \n",
    "    batch_size=batch_size, \n",
    "    validation_split=0.1, \n",
    "    subset='validation', \n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aac1187c-ed7c-4155-91ba-19934e11e258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1401 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'posts/posts_700', \n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "468135d6-dfee-47de-879b-9f8aefa7e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation),\n",
    "                                  '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b660bdfe-fee4-4ad2-a4b6-aa0b7529999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 15000\n",
    "sequence_length = 300\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dc6434b-9c2a-4bdc-97b3-b821b238cd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text = raw_train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)\n",
    "\n",
    "raw_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c9ed89-84d4-458a-9711-0e8dbca7a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4c64520-95ac-419e-bb58-0c081eed2731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review tf.Tensor(b\"Single Mom here. So, my oldest is almost 9. She came down with strep three days after school started back. Yay. =\\\\ Had a semi stressful weekend with trying to keep her and my youngest (almost 11 months) apart so the youngest wouldn't get infected too. However, the baby woke me up at 2am yesterday morning with a faucet for a nose and a slight cough. Called the doctor to see if that warranted a visit, and low and behold it does. She was also positive for strep. She's a really good baby though, and except for being off her bottle (I guess the sucking hurts?) a little bit, and hating to have her nose wiped, she's dealing amazingly well. \\n\\nSo to sum it up, I've got two sick kids and I'm behind on household chores (anyone got a laundry fairy they can spare??) and I'd really just like a night off from cooking dinner. I'm not desperate for food, and I totally understand if there are others who are and you'd rather help them. \\n\\nWe're in Metro Atlanta, and are happy with any of the three major chains, but we also have Hungry Howies and Bucks pizza who both have online ordering. My oldest only eats cheese, and I'll take any meat product on the other side. Allergies to mushrooms, so please none of those. :) \\n\\nI hope that's enough info.. but if not, feel free to ask me anything. :)\\n\", shape=(), dtype=string)\n",
      "Label pizza_700\n",
      "Vectorized review (<tf.Tensor: shape=(1, 300), dtype=int64, numpy=\n",
      "array([[ 576,  309,   58,   20,    7, 2774,   17,  395, 1145,  102,  388,\n",
      "         167,   26, 2529,  325,   93,  111,  203,  423,   76, 1150,   51,\n",
      "           5, 2000, 1274,  295,   26,  235,    4,  276,   92,    3,    7,\n",
      "        1905,  395, 1251,  161, 1399,   20,    6, 1905,  548,   28, 5522,\n",
      "         193,  392,    6,  690,  851,   14,   48,   37, 7316,  263,  399,\n",
      "          26,    5, 6079,    8,    5, 2785,    3,    5, 2578, 6526,  687,\n",
      "           6, 3116,    4,  260,   27,   23, 3530,    5,  810,    3,  401,\n",
      "           3, 2337,   13,  521,  102,   43,  125, 1173,    8, 2529,  511,\n",
      "           5,   41,  166,  690,  270,    3,  540,    8,  154,  119,   92,\n",
      "        1860,    2,  681,    6, 3935, 1200,    5,  123,  229,    3, 5754,\n",
      "           4,   12,   92, 2785, 2415,  511,  957, 3333,  122,   20,    4,\n",
      "        1432,   13,   48,   54,   83,  110,  390,  249,    3,   16,  596,\n",
      "          22, 1521, 3215,   78,   83,    5, 2878, 6092,   90,   34,  623,\n",
      "           3,   95,   41,   29,   55,    5,  135,  119,   50,  664,  182,\n",
      "          16,   32, 1021,    8,   42,    3,    2,  508,  671,   27,   79,\n",
      "          38,  677,  113,   38,    3,  617,  480,   33,  130,  104,   10,\n",
      "        2111, 1395,    3,   38,  299,   26,   71,    9,    6,  325,  714,\n",
      "        3225,   15,   30,  125,   12,  124, 5675,    3,  524,   11,  113,\n",
      "         245,   12,  591, 1181,    7, 2774,   87, 1810,  318,    3,  109,\n",
      "         218,   71,  785, 4597,   22,    6,  180,  921, 3335,    4, 1709,\n",
      "          20,  142,  936,    9,  326,    2,  255,  254,  158,  833,   15,\n",
      "          27,   32,  184,  330,    4,  234,   14,  121,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0]])>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "# retrieve a batch (of 32 reviews and labels) from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Review\", first_review)\n",
    "print(\"Label\", raw_train_ds.class_names[first_label])\n",
    "print(\"Vectorized review\", vectorize_text(first_review, first_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2a7d059-844f-4d3a-ad28-fcbe4063517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 7404\n"
     ]
    }
   ],
   "source": [
    "#print(\"1287 ---> \",vectorize_layer.get_vocabulary()[1287])\n",
    "#print(\" 313 ---> \",vectorize_layer.get_vocabulary()[313])\n",
    "print('Vocabulary size: {}'.format(len(vectorize_layer.get_vocabulary())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b41acf5b-2c56-466e-8a8d-cd9b759cf653",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "603c98d0-8bac-4600-9aa7-711c64316c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8184267-01a3-469c-b0e0-71379383d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63748493-4243-48ec-9a1b-2887caaaeb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          480032    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 32)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 32)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 480065 (1.83 MB)\n",
      "Trainable params: 480065 (1.83 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Embedding(max_features + 1, embedding_dim),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3393924-a675-469d-b4c2-7cce79afb4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 300), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6ea9005-767b-4c41-9d2f-56ad1595584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import losses\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=tf.keras.optimizers.legacy.Adam(learning_rate = 0.001),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af8484a9-19dd-4ede-9fb3-dfeffc8a6519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40/40 [==============================] - 2s 35ms/step - loss: 4.7767 - accuracy: 0.5028 - val_loss: 1.4630 - val_accuracy: 0.4786\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 1.2927 - accuracy: 0.5028 - val_loss: 1.2029 - val_accuracy: 0.4786\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 1s 29ms/step - loss: 1.1124 - accuracy: 0.5028 - val_loss: 1.0708 - val_accuracy: 0.4786\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 1.0003 - accuracy: 0.5028 - val_loss: 0.9658 - val_accuracy: 0.4786\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.9129 - accuracy: 0.5028 - val_loss: 0.8836 - val_accuracy: 0.4786\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.8459 - accuracy: 0.5028 - val_loss: 0.8214 - val_accuracy: 0.4786\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.7961 - accuracy: 0.5028 - val_loss: 0.7761 - val_accuracy: 0.4786\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.7604 - accuracy: 0.5036 - val_loss: 0.7447 - val_accuracy: 0.4786\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.7357 - accuracy: 0.5075 - val_loss: 0.7240 - val_accuracy: 0.4786\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 1s 28ms/step - loss: 0.7191 - accuracy: 0.5440 - val_loss: 0.7111 - val_accuracy: 0.4786\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    batch_size = 32,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2e5ead0-7ca2-4509-ae46-36f4dc1e6569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 5ms/step - loss: 0.6891 - accuracy: 0.5054\n",
      "Loss:  0.6891027688980103\n",
      "Accuracy:  0.5053533315658569\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f704ac2-07c9-4d48-8b1e-d0551381727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a learning rate schedule to reduce learning rate each epoch\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    initial_learning_rate = 0.001\n",
    "    decay_steps = 5\n",
    "    decay_rate = 0.5\n",
    "    lr = initial_learning_rate * (decay_rate ** (epoch // decay_steps))\n",
    "    return lr\n",
    "\n",
    "# Create the LearningRateScheduler callback\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3de048d5-d9d6-4c65-ab74-408c57bdf94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  tf.keras.backend.clear_session()\n",
    "  tf.random.set_seed(0)\n",
    "\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Embedding(\n",
    "      input_dim = max_features,  # size of feature vocabulary\n",
    "      output_dim = 4,  # embedding dimension\n",
    "      input_length = sequence_length  # number of inputs\n",
    "      ))\n",
    "\n",
    "  model.add(tf.keras.layers.Conv1D(filters=16,\n",
    "                                   strides = 3,\n",
    "                                   padding = 'same',\n",
    "                                   kernel_size=12, # length of word\n",
    "                                   activation='relu'))\n",
    "\n",
    "  # Average over the sequence dimension, so each review is represented by \n",
    "  # 1 vector of size embedding_dimension\n",
    "  model.add(tf.keras.layers.GlobalAveragePooling1D()) \n",
    "\n",
    "  # Alternatively, we could concatenate the embedding representations of \n",
    "  # all tokens in the movie review\n",
    "  #model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(\n",
    "      units=16,        \n",
    "      activation='relu'))\n",
    "\n",
    "  model.add(tf.keras.layers.Dense(\n",
    "      units=1,        \n",
    "      activation='sigmoid'))\n",
    "\n",
    "  model.compile(loss='binary_crossentropy', \n",
    "                optimizer=tf.keras.optimizers.legacy.Adam(),#learning_rate = 0.001), comment out to use learning rate schedule\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53d14596-a952-4ece-b28f-62ff90b0aca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.layers.core.embedding.Embedding at 0x2888d40d0>,\n",
       " <keras.src.layers.convolutional.conv1d.Conv1D at 0x111f88ac0>,\n",
       " <keras.src.layers.pooling.global_average_pooling1d.GlobalAveragePooling1D at 0x282dce130>,\n",
       " <keras.src.layers.core.dense.Dense at 0x288a55190>,\n",
       " <keras.src.layers.core.dense.Dense at 0x287d344f0>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 4)            60000     \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 100, 16)           784       \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 16)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61073 (238.57 KB)\n",
      "Trainable params: 61073 (238.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "# Display the model layers.\n",
    "display(model.layers)\n",
    "display(model.summary())\n",
    "\n",
    "# Retrieve the embeddings layer, which itself is wrapped in a list.\n",
    "embeddings = model.layers[-1].get_weights()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6dcda660-194a-4c88-936d-a5d96a2e1aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6939 - accuracy: 0.4980 - val_loss: 0.6930 - val_accuracy: 0.5643 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.6927 - accuracy: 0.5353 - val_loss: 0.6929 - val_accuracy: 0.4857 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.6920 - accuracy: 0.5599 - val_loss: 0.6926 - val_accuracy: 0.5357 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.6898 - accuracy: 0.5765 - val_loss: 0.6915 - val_accuracy: 0.5286 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.6825 - accuracy: 0.6098 - val_loss: 0.6898 - val_accuracy: 0.5429 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.6689 - accuracy: 0.6384 - val_loss: 0.6890 - val_accuracy: 0.5429 - lr: 5.0000e-04\n",
      "Epoch 7/15\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.6541 - accuracy: 0.6614 - val_loss: 0.6902 - val_accuracy: 0.5571 - lr: 5.0000e-04\n",
      "Epoch 8/15\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.6357 - accuracy: 0.6836 - val_loss: 0.6918 - val_accuracy: 0.5429 - lr: 5.0000e-04\n",
      "Epoch 9/15\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.6130 - accuracy: 0.7105 - val_loss: 0.6954 - val_accuracy: 0.5429 - lr: 5.0000e-04\n",
      "Epoch 10/15\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.5861 - accuracy: 0.7359 - val_loss: 0.7008 - val_accuracy: 0.5429 - lr: 5.0000e-04\n",
      "Epoch 11/15\n",
      "40/40 [==============================] - 1s 25ms/step - loss: 0.5619 - accuracy: 0.7637 - val_loss: 0.7032 - val_accuracy: 0.5429 - lr: 2.5000e-04\n",
      "Epoch 12/15\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5459 - accuracy: 0.7827 - val_loss: 0.7066 - val_accuracy: 0.5429 - lr: 2.5000e-04\n",
      "Epoch 13/15\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5302 - accuracy: 0.8002 - val_loss: 0.7100 - val_accuracy: 0.5286 - lr: 2.5000e-04\n",
      "Epoch 14/15\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.5142 - accuracy: 0.8105 - val_loss: 0.7143 - val_accuracy: 0.5214 - lr: 2.5000e-04\n",
      "Epoch 15/15\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.4986 - accuracy: 0.8200 - val_loss: 0.7190 - val_accuracy: 0.5286 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    batch_size = 16,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abffc9be-7b07-40dc-a659-f923f9ebb400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>giver_username_if_known</th>\n",
       "      <th>request_id</th>\n",
       "      <th>request_text_edit_aware</th>\n",
       "      <th>request_title</th>\n",
       "      <th>requester_account_age_in_days_at_request</th>\n",
       "      <th>requester_days_since_first_post_on_raop_at_request</th>\n",
       "      <th>requester_number_of_comments_at_request</th>\n",
       "      <th>requester_number_of_comments_in_raop_at_request</th>\n",
       "      <th>requester_number_of_posts_at_request</th>\n",
       "      <th>requester_number_of_posts_on_raop_at_request</th>\n",
       "      <th>requester_number_of_subreddits_at_request</th>\n",
       "      <th>requester_subreddits_at_request</th>\n",
       "      <th>requester_upvotes_minus_downvotes_at_request</th>\n",
       "      <th>requester_upvotes_plus_downvotes_at_request</th>\n",
       "      <th>requester_username</th>\n",
       "      <th>unix_timestamp_of_request</th>\n",
       "      <th>unix_timestamp_of_request_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N/A</td>\n",
       "      <td>t3_i8iy4</td>\n",
       "      <td>Hey all! It's about 95 degrees here and our ki...</td>\n",
       "      <td>[request] pregger gf 95 degree house and no fo...</td>\n",
       "      <td>42.083866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>[AskReddit, COents, Denver, DenverBroncos, Lib...</td>\n",
       "      <td>364</td>\n",
       "      <td>840</td>\n",
       "      <td>j_like</td>\n",
       "      <td>1308963419</td>\n",
       "      <td>1308959819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  giver_username_if_known request_id  \\\n",
       "0                     N/A   t3_i8iy4   \n",
       "\n",
       "                             request_text_edit_aware  \\\n",
       "0  Hey all! It's about 95 degrees here and our ki...   \n",
       "\n",
       "                                       request_title  \\\n",
       "0  [request] pregger gf 95 degree house and no fo...   \n",
       "\n",
       "   requester_account_age_in_days_at_request  \\\n",
       "0                                 42.083866   \n",
       "\n",
       "   requester_days_since_first_post_on_raop_at_request  \\\n",
       "0                                                0.0    \n",
       "\n",
       "   requester_number_of_comments_at_request  \\\n",
       "0                                       57   \n",
       "\n",
       "   requester_number_of_comments_in_raop_at_request  \\\n",
       "0                                                0   \n",
       "\n",
       "   requester_number_of_posts_at_request  \\\n",
       "0                                    10   \n",
       "\n",
       "   requester_number_of_posts_on_raop_at_request  \\\n",
       "0                                             0   \n",
       "\n",
       "   requester_number_of_subreddits_at_request  \\\n",
       "0                                         16   \n",
       "\n",
       "                     requester_subreddits_at_request  \\\n",
       "0  [AskReddit, COents, Denver, DenverBroncos, Lib...   \n",
       "\n",
       "   requester_upvotes_minus_downvotes_at_request  \\\n",
       "0                                           364   \n",
       "\n",
       "   requester_upvotes_plus_downvotes_at_request requester_username  \\\n",
       "0                                          840             j_like   \n",
       "\n",
       "   unix_timestamp_of_request  unix_timestamp_of_request_utc  \n",
       "0                 1308963419                     1308959819  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_json(\"test.json\")\n",
    "test_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d023511-92f5-45e5-b98d-7d2e82714fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_csv(predictions):\n",
    "  test_data['request_text_edit_aware'] = predictions.reshape(-1).round().astype(int) # turns 0.6 into 1, 0.4 into 0, etc. since we just want 1s and 0s\n",
    "  display(df_test.head(10))\n",
    "  filename = 'titanic_predictions.csv'\n",
    "  df_test.to_csv(\n",
    "      filename,\n",
    "      columns=['PassengerId', 'Survived'],\n",
    "      index=False)\n",
    "  print('Saved as:', filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
